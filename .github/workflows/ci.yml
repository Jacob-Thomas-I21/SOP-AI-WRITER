name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  # Backend Testing
  backend-test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        cd backend
        python -m pip install --upgrade pip
        # Clear pip cache to ensure fresh installation
        pip cache purge
        # Force reinstall pydantic with email support
        pip install --force-reinstall "pydantic[email]==2.5.0"
        pip install -r requirements.txt

        # Verify email-validator is installed
        echo "Verifying email-validator installation..."
        python -c "import email_validator; print('‚úÖ email-validator installed successfully')" || (echo "‚ùå email-validator not found" && exit 1)

    - name: Run backend tests
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
        REDIS_URL: redis://localhost:6379/0
        SECRET_KEY: test-secret-key-for-ci
        PYTHONPATH: ${{ github.workspace }}/backend
      run: |
        cd backend
        python -c "from app.core.database import init_db; init_db()"
        PYTHONPATH=$PWD pytest tests/ -v --cov=app --cov-report=xml --cov-report=term -m "not external_service"

    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./backend/coverage.xml
        flags: backend
        name: backend-coverage
        fail_ci_if_error: false

  # Frontend Testing
  frontend-test:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json

    - name: Install dependencies
      run: |
        cd frontend
        npm ci

    - name: Run frontend tests
      run: |
        cd frontend
        npm run type-check
        npm run lint

    - name: Build frontend
      run: |
        cd frontend
        npm run build

  # Security Scanning
  security-scan:
    runs-on: ubuntu-latest
    permissions:
      actions: read
      contents: read
      security-events: write

    steps:
    - uses: actions/checkout@v4

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'

    - name: Upload Trivy scan results to GitHub Security tab
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'

  # Dependency Check
  dependency-check:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Check Python dependencies
      run: |
        cd backend
        pip install safety
        safety check --file requirements.txt --output json || true

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'

    - name: Check Node.js dependencies
      run: |
        cd frontend
        npm install
        npx audit-ci --config audit-ci.json || true

  # Code Quality
  code-quality:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install Python quality tools
      run: |
        python -m pip install --upgrade pip
        pip install black isort flake8 mypy

    - name: Check Python code quality
      run: |
        cd backend
        black --check --diff app/ || echo "Black formatting issues found - run 'black app/' to fix"
        isort --check-only --diff app/ || echo "Import sorting issues found - run 'isort app/' to fix"
        flake8 app/ --max-line-length=88 --extend-ignore=E203,W503 || echo "Flake8 issues found"
        mypy app/ --ignore-missing-imports || echo "MyPy type checking issues found"

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'

    - name: Check frontend code quality
      run: |
        cd frontend
        npm install
        npm run lint
        npm run type-check

  # Docker Build Test (Optional - Comment out if not needed)
  docker-build:
    runs-on: ubuntu-latest
    if: contains(github.event.head_commit.message, '[docker]') || contains(github.event.head_commit.message, '[build]') || github.event_name == 'workflow_dispatch'

    steps:
    - uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Build backend Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./local-deployment/docker/Dockerfile.backend
        push: false
        tags: pharmaceutical-sop-author-backend:test
        cache-from: type=gha
        cache-to: type=gha,mode=max

    - name: Build frontend Docker image
      run: |
        docker build -f ./frontend/Dockerfile ./frontend -t pharmaceutical-sop-author-frontend:test || echo "Frontend Dockerfile not found, skipping"

  # Compliance Check
  compliance-check:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Check for sensitive data
      run: |
        # Check for hardcoded sensitive data (exclude config files and legitimate defaults)
        echo "üîç Scanning for hardcoded sensitive data..."

        # Only look for actual hardcoded sensitive values, exclude config files
        sensitive_patterns=(
          # Real passwords: variable_name = "actual_password_value" (exclude config files)
          "[a-zA-Z_][a-zA-Z0-9_]*[[:space:]]*=[[:space:]]*['\"][^'\"]{12,}['\"]"
          # Real API Keys: api_key = "sk-1234567890abcdef" (exclude config files)
          "api_key[[:space:]]*=[[:space:]]*['\"][a-zA-Z0-9_-]{25,}['\"]"
          # Real JWT Tokens: token = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9" (exclude config files)
          "token[[:space:]]*=[[:space:]]*['\"][a-zA-Z0-9_.-]{60,}['\"]"
          # Real Secrets: secret = "actual_secret_value" (exclude config files)
          "secret[[:space:]]*=[[:space:]]*['\"][^'\"]{15,}['\"]"
          # Private keys: private_key = "-----BEGIN PRIVATE KEY-----"
          "private_key[[:space:]]*=[[:space:]]*['\"]-{5}[^'\"]*-{5}['\"]"
        )

        found_sensitive=false

        # Check each pattern, specifically excluding config files and legitimate defaults
        for pattern in "${sensitive_patterns[@]}"; do
          # Exclude config files, environment variable references, and test files
          matches=$(grep -r -E "$pattern" --include="*.py" --include="*.ts" --include="*.js" --include="*.json" --include="*.env*" . --exclude-dir=.git --exclude-dir=node_modules --exclude-dir=__pycache__ 2>/dev/null | grep -v "config.py" | grep -v "settings" | grep -v "example" | grep -v "template" | grep -v "test" | grep -v "mock" | grep -v "fake" | grep -v "sample" | grep -v "default" | grep -v "placeholder" | grep -v "change-in-production" | grep -v "sqlite://" | grep -v "redis://" | grep -v "localhost" | head -5)

          if [ ! -z "$matches" ]; then
            echo "‚ö†Ô∏è  Potential hardcoded sensitive data found:"
            echo "$matches"
            echo ""
            found_sensitive=true
          fi
        done

        # Check for suspicious patterns in non-config files only
        suspicious_patterns=(
          # Hardcoded database passwords
          "password[[:space:]]*=[[:space:]]*['\"][^'\"]{8,}['\"]"
          # Hardcoded connection strings with credentials
          "(postgres|mysql|mongodb)://[^'\"]*:[^'\"]*@"
          # AWS access keys
          "AKIA[0-9A-Z]{16}"
          # Generic secret patterns in non-config files
          "SECRET[[:space:]]*=[[:space:]]*['\"][^'\"]{10,}['\"]"
        )

        for pattern in "${suspicious_patterns[@]}"; do
          matches=$(grep -r -E "$pattern" --include="*.py" --include="*.ts" --include="*.js" --include="*.json" --include="*.env*" . --exclude-dir=.git --exclude-dir=node_modules --exclude-dir=__pycache__ 2>/dev/null | grep -v "config.py" | grep -v "settings" | grep -v "example" | grep -v "template" | grep -v "test" | grep -v "mock" | head -3)

          if [ ! -z "$matches" ]; then
            echo "‚ö†Ô∏è  Suspicious pattern found:"
            echo "$matches"
            echo ""
            found_sensitive=true
          fi
        done

        if [ "$found_sensitive" = true ]; then
          echo "‚ùå Sensitive data check failed - review findings above"
          echo "üí° Tip: Move sensitive values to environment variables or .env files"
          exit 1
        else
          echo "‚úÖ No hardcoded sensitive data found"
        fi

    - name: Check file permissions
      run: |
        find . -name "*.sh" -o -name "*.py" -o -name "*.js" | xargs ls -la | awk '{if ($1 ~ /x/) print "Executable file:", $9}'

    - name: Validate JSON/YAML files
      run: |
        find . -name "*.json" -o -name "*.yml" -o -name "*.yaml" | while read file; do
          if ! python -c "import json; json.load(open('$file'))" 2>/dev/null && ! python -c "import yaml; yaml.safe_load(open('$file'))" 2>/dev/null; then
            echo "Invalid JSON/YAML: $file"
            exit 1
          fi
        done
        echo "‚úÖ All JSON/YAML files are valid"